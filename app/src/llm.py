from langchain_core.prompts import PromptTemplate
from langchain_ollama import OllamaLLM


class Llm:
    """
    A class to handle generating answers using a language model (LLM) based on a given context and query.
    """
    def __init__(self):
        """
        Initializes the LLM class.

        This sets up the LLM instance with a specific model. In this case, the model used is "llama3.2".
        """
        self.llm = OllamaLLM(model="llama3.2")

    def generate_answer(self, query_text, relevant_context):
        """
        Generates an answer to a query based on the provided context using the LLM.

        Args:
            query_text (str): The user's question or query.
            relevant_context (str): The context or information against which the query should be answered.

        Returns:
            str: The answer generated by the LLM
        """
        
        prompt_extract = PromptTemplate.from_template(
            """
            You are a chatbot that answers questions strictly based on context. 
            
            CONTEXT information is below:
            ------------------------
            {context}
            ------------------------

            Given the context information and not prior knowledge,
            answer the following query:
            QUERY: {query_text}
            
            If the CONTEXT does not contain the facts to answer the QUERY, return "I am sorry, this question is out of my domain."

            Answer:
            """
        )

        chain_extract = prompt_extract | self.llm  
        res = chain_extract.invoke(input={'context': relevant_context, 'query_text': query_text})
        return res